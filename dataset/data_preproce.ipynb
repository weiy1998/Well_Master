{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 井控微调数据集的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = r'C:/Users/yanwei/Desktop/CQU/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "QA_path = os.path.join(root_path, 'book1_classified.xlsx')\n",
    "data = pd.read_excel(QA_path, sheet_name='choice') # 读取选择题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data[['题目', '答案', '易错选项', 'Unnamed: 6', 'Unnamed: 7', '题目+答案']]\n",
    "data1 = data1.rename(columns={'易错选项':'易错1', 'Unnamed: 6':'易错2', 'Unnamed: 7':'易错3', '题目+答案':'完整描述'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将所有的nan 替换为“无”\n",
    "data1 = data1.fillna('无')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将列名与每一行的值组成键值对\n",
    "data1 = data1.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(root_path, 'convert_kv_format.json'), 'w', encoding='utf-8') as f:\n",
    "    json.dump(data1, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ZhipuAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**智谱API调用**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同步调用\n",
    "from zhipuai import ZhipuAI  # 先安装ZhipuAI的包 pip install ZhipuAI\n",
    "client = ZhipuAI(api_key=\"d96b3dc3c1b2ce95e379396f4d5d6da1.B55pm2il4dXs8822\") # 填写您自己的APIKey\n",
    "response = client.chat.completions.create(\n",
    "    model=\"glm-4\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "    # messages是json格式的数据，大模型逐条响应\n",
    "        {\"role\": \"user\", \"content\": \"作为一名营销专家，请为我的产品创作一个吸引人的slogan\"},\n",
    "        # {\"role\": \"assistant\", \"content\": \"当然，为了创作一个吸引人的slogan，请告诉我一些关于您产品的信息\"},\n",
    "        # {\"role\": \"user\", \"content\": \"智谱AI开放平台\"},\n",
    "        # {\"role\": \"assistant\", \"content\": \"智启未来，谱绘无限一智谱AI，让创新触手可及!\"},\n",
    "        # {\"role\": \"user\", \"content\": \"创造一个更精准、吸引人的slogan\"}\n",
    "    ],\n",
    ")\n",
    "# 直接输出response，查看响应的具体内容\n",
    "# print(response)\n",
    "print(response.choices[0].message.content) # \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zhipuai import ZhipuAI\n",
    "client = ZhipuAI(api_key='d96b3dc3c1b2ce95e379396f4d5d6da1.B55pm2il4dXs8822')\n",
    "\n",
    "while True:\n",
    "    prompt = input('\\n user: ')\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"glm-4\",\n",
    "        messages = [\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ],\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "    print('\\n answer: ', answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 异步调用\n",
    "import time\n",
    "from zhipuai import ZhipuAI\n",
    "client = ZhipuAI(api_key=\"d96b3dc3c1b2ce95e379396f4d5d6da1.B55pm2il4dXs8822\") # 请填写您自己的APIKey\n",
    "\n",
    "response = client.chat.asyncCompletions.create(\n",
    "    model=\"glm-4\",  # 填写需要调用的模型名称\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"请你作为童话故事大王，写一篇短篇童话故事，故事的主题是要永远保持一颗善良的心，要能够激发儿童的学习兴趣和想象力，同时也能够帮助儿童更好地理解和接受故事中所蕴含的道理和价值观。\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "# 获取响应ID\n",
    "task_id = response.id\n",
    "task_status = ''\n",
    "get_cnt = 0\n",
    "\n",
    "while task_status != 'SUCCESS' and task_status != 'FAILED' and get_cnt <= 40:\n",
    "    # 查询响应结果\n",
    "    result_response = client.chat.asyncCompletions.retrieve_completion_result(id=task_id)\n",
    "    print(result_response)\n",
    "    task_status = result_response.task_status\n",
    "\n",
    "    time.sleep(2)\n",
    "    get_cnt += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## zhipu 文生图大模型调用\n",
    "\n",
    "from zhipuai import ZhipuAI\n",
    "client = ZhipuAI(api_key='d96b3dc3c1b2ce95e379396f4d5d6da1.B55pm2il4dXs8822')\n",
    "\n",
    "response = client.images.generations(\n",
    "    model='cogview-3',\n",
    "    prompt='一只小狗'\n",
    ")\n",
    "print(response.data[0].url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Qwen API调用**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单论对话\n",
    "import random\n",
    "from http import HTTPStatus\n",
    "import dashscope\n",
    "\n",
    "dashscope.api_key = 'sk-029ca2483e6749a0aceff839174a9945'\n",
    "\n",
    "def call_with_messages():\n",
    "    prompt = input(\"user:\")\n",
    "    messages = [{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "                {'role': 'user', 'content': prompt}]\n",
    "    response = dashscope.Generation.call(\n",
    "        dashscope.Generation.Models.qwen_turbo, # 选择模型\n",
    "        messages=messages,\n",
    "        # set the random seed, optional, default to 1234 if not set\n",
    "        seed=random.randint(1, 10000),\n",
    "        result_format='message',  # set the result to be \"message\" format.\n",
    "    )\n",
    "    # 之后HTTPStatus为OK时，才是调用成功\n",
    "    if response.status_code == HTTPStatus.OK:\n",
    "        print(response)\n",
    "    else:\n",
    "        print('Request id: %s, Status code: %s, error code: %s, error message: %s' % (\n",
    "            response.request_id, response.status_code,\n",
    "            response.code, response.message\n",
    "        ))\n",
    "\n",
    "def call_with_prompt():\n",
    "    prompt = input(\"user:\")\n",
    "    response = dashscope.Generation.call(\n",
    "        model=dashscope.Generation.Models.qwen_turbo, # 选择模型\n",
    "        prompt=prompt\n",
    "    )\n",
    "    # The response status_code is HTTPStatus.OK indicate success,\n",
    "    # otherwise indicate request is failed, you can get error code\n",
    "    # and message from code and message.\n",
    "    if response.status_code == HTTPStatus.OK:\n",
    "        print(response.output)  # The output text\n",
    "        print(response.usage)  # The usage information\n",
    "    else:\n",
    "        print(response.code)  # The error code.\n",
    "        print(response.message)  # The error message.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    call_with_messages()\n",
    "    print(\"\\n\")\n",
    "    call_with_prompt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 多轮对话调用\n",
    "from http import HTTPStatus\n",
    "import dashscope\n",
    "from dashscope import Generation\n",
    "from dashscope.api_entities.dashscope_response import Role\n",
    "\n",
    "dashscope.api_key = 'sk-029ca2483e6749a0aceff839174a9945' # 设置API_KEY\n",
    "\n",
    "def conversation_with_messages():\n",
    "    messages = [{'role': Role.SYSTEM, 'content': 'You are a helpful assistant.'}  ]\n",
    "    # 循环实现多轮会话\n",
    "    while True:\n",
    "        prompt = input(\"USER:\")\n",
    "        # 添加新一轮会话用户的问题\n",
    "        messages.append({'role': Role.USER, 'content': prompt})\n",
    "        response = Generation.call(\n",
    "            Generation.Models.qwen_turbo, #选择响应的模型\n",
    "            messages=messages,\n",
    "            result_format='message',  # set the result to be \"message\" format.\n",
    "        )\n",
    "        if response.status_code == HTTPStatus.OK:\n",
    "            print(response)\n",
    "            # 把模型的输出添加到messages中\n",
    "            messages.append({'role': response.output.choices[0]['message']['role'],\n",
    "                             'content': response.output.choices[0]['message']['content']})\n",
    "        else:\n",
    "            print('Request id: %s, Status code: %s, error code: %s, error message: %s' % (\n",
    "                response.request_id, response.status_code,\n",
    "                response.code, response.message\n",
    "            ))\n",
    "            exit()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    conversation_with_messages()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过openai 进行调用\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "try:\n",
    "    client = OpenAI(\n",
    "        api_key='sk-029ca2483e6749a0aceff839174a9945',\n",
    "        base_url='https://dashscope.aliyuncs.com/compatible-mode/v1',\n",
    "    )\n",
    "    \n",
    "    completion = client.completions.create(\n",
    "        model='qwen-turbo',\n",
    "        messages = [\n",
    "            {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "            {'role': 'user', 'content': '你是谁？'}\n",
    "        ]\n",
    "    )\n",
    "    print(completion.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(f'错误信息：{e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ollama 调用本地大模型**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "res=ollama.chat(model=\"qwen2.5:7b\",stream=False,messages=[{\"role\": \"user\",\"content\": \"你是谁\"}],options={\"temperature\":0})\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "你好！很高兴能为你提供帮助。有什么问题我可以回答吗？\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from http import HTTPStatus\n",
    "import dashscope\n",
    "\n",
    "dashscope.api_key = 'sk-029ca2483e6749a0aceff839174a9945'\n",
    "\n",
    "def call_with_messages(prompt):\n",
    "    # prompt = input(\"user:\")\n",
    "    messages = [{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
    "                {'role': 'user', 'content': prompt}]\n",
    "    response = dashscope.Generation.call(\n",
    "        dashscope.Generation.Models.qwen_turbo, # 选择模型\n",
    "        messages=messages,\n",
    "        # set the random seed, optional, default to 1234 if not set\n",
    "        seed=random.randint(1, 10000),\n",
    "        result_format='message',  # set the result to be \"message\" format.\n",
    "    )\n",
    "    # 之后HTTPStatus为OK时，才是调用成功\n",
    "    if response.status_code == HTTPStatus.OK:\n",
    "        # print(response)\n",
    "        return response.output.choices[0]['message']['content']\n",
    "    else:\n",
    "        print('Request id: %s, Status code: %s, error code: %s, error message: %s' % (\n",
    "            response.request_id, response.status_code,\n",
    "            response.code, response.message\n",
    "        ))\n",
    "\n",
    "\n",
    "def call_with_prompt(prompt):\n",
    "    # prompt = input(\"user:\")\n",
    "    response = dashscope.Generation.call(\n",
    "        model=dashscope.Generation.Models.qwen_turbo, # 选择模型\n",
    "        prompt=prompt\n",
    "    )\n",
    "    # The response status_code is HTTPStatus.OK indicate success,\n",
    "    # otherwise indicate request is failed, you can get error code\n",
    "    # and message from code and message.\n",
    "    if response.status_code == HTTPStatus.OK:\n",
    "        return response.output.text\n",
    "        # print(response.output)  # The output text\n",
    "        # print(response.usage)  # The usage information\n",
    "    else:\n",
    "        print(response.code)  # The error code.\n",
    "        print(response.message)  # The error message.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    prompt = input('user: ')\n",
    "    # print(call_with_messages(prompt))\n",
    "    # print(\"\\n\")\n",
    "    print(call_with_prompt(prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
